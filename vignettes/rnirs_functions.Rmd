---
title: "R Package rnirs"
#author: "Matthieu Lesnoff (Cirad, UMR Selmet, Montpellier, France)"
#date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Examples of data analyses}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

**https://github.com/mlesnoff/rnirs**

## DIMENSION REDUCTION

### <span style="color:green"> PCA </span> 

- ***pca*** PCA with the available algorithms below

- **Algorithms for usual PCA**

  - ***pca_eigen*** EIGEN decomposition
  - ***pca_eigenk*** EIGEN for wide matrices (kernel form)
  - ***pca_svd*** SVD decomposition
  - ***pca_nipals*** NIPALS
  - ***pca_nipalsna*** NIPALS allowing missing data
  
- **Algorithms for robust PCA**
  
  - ***pcasph*** Spherical PCA (Locantore 1999) \cr
  - ***pcacr*** Projection-Pursuit PCA (Croux & Ruiz-Gazen 2005)
  - ***pcarob*** Robust weighting

### <span style="color:green"> PLS </span>

- ***pls*** PLS with the available algorithms below.

- **Algorithms for usual PLS**

  - ***pls_kernel*** "Improved Kernel #1" (Dayal & McGregor 1997)
  - ***pls_nipals*** NIPALS
  - ***pls_rannar*** Kernel version for wide matrices (Rannar et al. 1994)

- **Algorithms for robust PLS1**

  - ***pls_iw*** Iterative re-weighting
  - ***pls_rob*** Weighting

### <span style="color:green"> FDA </span>

- ***fda*** Using EIGEN decomposition of a compromise
- ***fdasvd*** Using weighted SVD decomposition of class centers

### <span style="color:green"> Non Linear Kernel </span>

- **KPCA (Scholkopf et al. 2002)**

  - ***kpca*** EIGEN decomposition

- **KPLS (Rosipal & Trejo 2001)**

  - ***kpls*** (uses ***kpls_nipals***)
  - ***kpls_nipals*** NIPALS  

- **Direct KPCA and KPLS (Bennett & Embrechts 2003)**

  - ***kgram*** Build Gram matrices for direct kernel models
  
- **Available kernel functions**

  - ***kpol*** Polynomial
  - ***krbf*** Gausssian RBF
  - ***ktanh*** Hyperbolic tangent

### <span style="color:green"> Multi-block </span> 

- ***blocksel*** Block selection in a matrix
- ***blockpls*** Block dimension reduction by PLS
- ***blockscal*** Block autoscaling: Used for MB-PLS or MB-PCA 
- ***blocksopca*** Block dimension reduction by SO-PCA (sequential orthogonalization)
- ***blocksopls*** Block dimension reduction by SO-PLS (sequential orthogonalization)
- ***orthog*** Orthogonalization of a matrix to another matrix

### <span style="color:green"> Outlyingness Multivariate Measures (Outliers) </span> 

- ***outeucl*** Outlyingness using Euclidean distance
- ***outsdod*** Outlyingness based on a score space
- ***outstah*** Stahel-Donoho outlyingness

### <span style="color:green"> Auxilliary functions </span>

- ***scordis***, ***lscordis*** Score distances for a score space
- ***odis***, ***lodis*** Orthogonal distances for a score space
- ***xfit*** Matrix fitting from multivariate scores and loadings, 
- ***xssr*** SSR calculation for a matrix fitting

## REGRESSION

### <span style="color:green"> Linear </span> 

- ***lmr*** Multiple linear regression
- ***rr*** Ridge Regression

- **On latent variables**

  - ***pcr*** PCR
  - ***plsr*** PLSR
  - **Auxiliary functions**
    - ***bcoef*** b-coefficients for PLSR and PCR models
    - Same other auxiliary functions as for PCA & PLS

### <span style="color:green"> Non Linear </span> 

- ***inlr*** Blocks for INLR (Berglund & Wold 1997)

- **Kernel**

  - ***krr*** Kernel ridge regression (LS-SVM)
  - ***svmr*** SVM regression
  - **On latent variables**
    - Using functions ***kpca*** and ***kpls_nipals***
      - ***kpcr*** Kernel PCR
      - ***kplsr*** Kernel PLSR
    - Direct KPCR and KPLSR
      - ***dkplsr***
      - Or use ***kgram***
      
- **Locally weighted**

  - ***knnr*** KNN regression
  - ***lwplsr*** KNN-LWPLSR
  - **Generic function**
    - ***locw*** building KNN-locally weighted models
      
## DISCRIMINATION (DA) 

### <span style="color:green"> DA methods </span> 

- **Probabilistic**

  - ***daprob*** Probablistic (parametric and non-parametric) LDA and QDA

- **Distance-based**

  - ***dadis*** Using the dissimilarity to the class centers
  - ***dasdod*** Using a Simca index

- **Linear on the Y-dummy table**
  - ***daglm*** Using generalized linear models
  - ***dalm*** Using multivariate linear regression
  - ***darr*** Using linear ridge regression
  
### <span style="color:green"> Linear </span> 

- **On latent variables**
  - ***pcda*** PCDA using any above DA method
  - ***pcdalm*** same as ***pcda(dalm)*** but faster
  - ***plsda*** PLSDA using any above DA method
  - ***plsdalm*** same as ***plsda(dalm)*** but faster
  
### <span style="color:green"> Non Linear </span> 
  
- **Kernel**
  - ***dakrr*** Using kernel ridge regression
  - ***svmc*** SVM classification
  - **On latent variables**
    - Using functions ***kpca*** and ***kpls_nipals***
      - ***kpcda*** Kernel PCDA using any above DA method
      - ***kpcdalm*** Same as ***kpcda(dalm)*** but faster
      - ***kplsda*** Kernel PLSDA using any above DA method
      - ***kplsdalm*** Same as ***kplsda(dalm)*** but faster
    - Direct KPCDA and KPLSDA 
      - ***dkplsda***
      - ***dkplsdalm***
      - Or use ***kgram***
 
- **Locally weighted** (see ***locw***)

  - ***knnda*** KNN DA
  - ***lwplsda*** KNN-LWPLSDA

## MODEL STACKING

- ***stackavg*** Stacking for regression models 
- ***stackavgcla*** Stacking for discrimination models

## CROSS-VALIDATION, ERROR RATES, DEGREES OF FREEDOM (DOF)

- ***segmkf*** Building segments for K-Fold CV
- ***segmts*** Building segments for test-set CV
- ***cvfit*** Generic function for cross-validating a model
- **Specific CV for PCA**
  - ***cvpcaia*** IA algorithm
  - ***cvpcatri*** ekf-TRI algorithm
  - ***cvpcackf*** ckf-TRI algorithm
  - ***cvpcarw*** Row-wise algorithm
- **Model complexity (df)**
  - ***dfplsrcov***, ***dfplsrdiv*** Monte Carlo estimation of df for PLSR1 models 
  - ***dfpcadiv*** Monte Carlo estimation of df for PCA models 
- **Mallows Cp**
  - ***cpplsr*** Mallows Cp criterion for PLSR1 models
  - ***cppca*** Mallows Cp criterion for PCA models
- **Prediction error rate**
  - ***mse*** For regression models
  - ***err*** For discrimination models
  - ***plotmse*** Plotting error rates of prediction models
  - ***selwold*** Wold's criterion for selecting the number of components in PCR/DA and PLSR/DA model

## SELECTION OF VARIABLES 

- ***covsel*** COVSEL algorithm

## MODEL TUNING

- ***splitpar*** Split the value of a parameter within an interval

## DATA PRE-PROCESSING 

- ***dderiv*** Derivation by finite difference
- ***detrend*** Detrend transformation (polynom, lowess, als)
- ***mavg*** Smoothing by moving average
- ***savgol*** Savitsky-Golay filtering (derivation)
- ***snv*** Standard-normal-deviation transformation

## DATA SAMPLING 

- ***sampclas*** Within-class (stratified) sampling
- ***sampdp*** Duplex sampling 
- ***sampks*** Kennard-Stone sampling 

## DATA MANAGEMENT

### <span style="color:green"> Checking </span> 

- ***checkdupl*** Find duplicated row observations between two data sets 
- ***rmdupl*** Remove duplicated row observations between two data sets
- ***checkna*** Find and count NA values in a data set

### <span style="color:green"> Summary </span> 

- ***centr*** Centers of classes
- ***dtaggregate*** Summary statistics with data subsets
- ***summ*** Summary of the variables of a data set

## MISSING DATA IMPUTATION

- ***ximputia*** PCA iterative algorithm (IA)

## GRAPHICS

- ***plotsp***, ***plostsp1*** Plotting spectra, loadings, or more generally row observations of a data set
- ***plotxy*** 2-d scatter plot
- ***plotjit*** Jittered plot
- ***plotxna*** Plotting missing data in a matrix

## AUXILIARY

- ***dis*** Dissimilarities between row observations of a matrix and a given vector
- ***dkerngauss***, ***dmnorm*** Prediction of probability density of multivariate data 
- ***dummy*** Table of dummy variables
- ***headm*** Return the first part of a matrix or data frame
- ***getknn*** KNN selection
- ***matB***, ***matW*** Between and within covariance matrices
- ***matdis*** Dissimilarity matrix (between observations)
- ***pinv*** Moore-Penrose pseudo-inverse
- ***sourcedir*** Source every R functions in a directory
- ***wdist*** Weights for distances
- See also the ***auxiliary functions*** in files **z...R**

## AUTHOR

**Matthieu Lesnoff**

- Cirad, [**UMR Selmet**](https://umr-selmet.cirad.fr/en), Montpellier, France

- [**ChemHouse**](https://www.chemproject.org/ChemHouse), Montpellier

**matthieu.lesnoff@cirad.fr**

### How to cite

Lesnoff, M. 2020. R package rnirs: Dimension reduction, Regression and Discrimination for Chemometrics. https://github.com/mlesnoff/rnirs. CIRAD, UMR SELMET, Montpellier, France


